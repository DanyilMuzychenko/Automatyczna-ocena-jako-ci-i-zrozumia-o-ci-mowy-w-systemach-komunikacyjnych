# EN
# ðŸŽ§ Non-Intrusive Speech Quality Assessment (MOS Estimation)

> âš ï¸ **Work in progress**  
> This repository contains an ongoing MSc thesis project.  
> The codebase, experiments, and documentation are still under active development.

---

## ðŸ“Œ Project Overview

The goal of this project is to design and evaluate **artificial intelligence models for automatic, non-intrusive estimation of speech quality**, expressed as **Mean Opinion Score (MOS)**, without the involvement of human listeners.

The work investigates whether modern deep learning techniques can reliably predict **subjective speech quality ratings** based solely on acoustic features or raw audio signals, achieving performance comparable to human assessment.

The project is developed as part of a **masterâ€™s thesis** and is still in progress.

---

## ðŸ§  Model Architectures

Several neural network architectures are evaluated, depending on the type of acoustic representation used.

### 1ï¸âƒ£ CNN-based models (Mel-spectrograms & MFCC)

For **Mel-spectrogram** and **MFCC** features, the following architectures are implemented:

- **CNN**  
  Pure convolutional neural network operating on 2D timeâ€“frequency representations.

- **CNN + GRU**  
  Convolutional feature extractor followed by a GRU layer to capture temporal dependencies.

- **CNN + LSTM**  
  Similar to CNN+GRU, using LSTM units for sequence modeling.

Each architecture is trained **independently** for Mel-spectrograms and MFCC features.

---

### 2ï¸âƒ£ wav2vec2.0-based models

For raw audio processing, pretrained self-supervised models are used:

- **wav2vec2.0 + GRU**
- **wav2vec2.0 + LSTM**

In this setup, wav2vec2.0 acts as a feature extractor, producing high-level speech embeddings, which are then processed by recurrent layers.

> CNN-based architectures are **not applied** to wav2vec2.0 embeddings.

---

## ðŸŽ¼ Acoustic Feature Extraction

The following acoustic representations are used in the project:

| Feature | Supported models |
|------|------------------|
| Mel-spectrogram | CNN / CNN+GRU / CNN+LSTM |
| MFCC | CNN / CNN+GRU / CNN+LSTM |
| wav2vec2.0 embeddings | wav2vec2 + GRU / LSTM |

No explicit statistical normalization (e.g., meanâ€“variance normalization) of acoustic features is applied. Feature scaling is handled implicitly by neural network layers.

---

## ðŸŽ¯ MOS Scaling

MOS values are linearly normalized during training to the range:

\[
\text{MOS}_{norm} = \frac{\text{MOS} - 1}{4}
\]

For evaluation and visualization, predictions are rescaled back to the standard **MOS âˆˆ [1, 5]** range.

---

## ðŸ“Š Evaluation Metrics

Model performance is evaluated using the following metrics:

- **MSE (Mean Squared Error)**
- **RMSE (Root Mean Squared Error)**
- **Pearson Correlation Coefficient**
- **Spearman Rank Correlation Coefficient**

Metrics are computed on the validation set.

---

## ðŸ“‚ Dataset

Experiments are conducted using the **NISQA Corpus**, which contains diverse speech samples with various degradations, annotated with subjective MOS ratings.

---

## ðŸš§ Project Status

- âœ” Feature extraction pipelines implemented  
- âœ” Multiple neural network architectures implemented  
- âœ” Training and validation framework completed  
- ðŸ”„ Hyperparameter tuning in progress  
- ðŸ”„ Extended evaluation and result analysis in progress  
- ðŸ”„ Documentation and thesis writing in progress  

---

## ðŸ“Œ Notes

This repository reflects an **experimental research setup**.  
The structure, models, and evaluation procedures may evolve as the thesis work progresses.

---

## ðŸ“„ License

This project is developed for academic research purposes.


# PL
# ðŸŽ§ Non-Intrusive Speech Quality Assessment (Estymacja MOS)

> âš ï¸ **Projekt w trakcie realizacji**  
> Repozytorium zawiera kod oraz eksperymenty realizowane w ramach pracy magisterskiej.  
> Implementacja, eksperymenty oraz dokumentacja sÄ… nadal rozwijane.

---

## ðŸ“Œ Opis projektu

Celem niniejszego projektu jest opracowanie oraz ocena modeli sztucznej inteligencji umoÅ¼liwiajÄ…cych **automatycznÄ…, nieinwazyjnÄ… estymacjÄ™ jakoÅ›ci mowy**, wyraÅ¼onej za pomocÄ… wskaÅºnika **MOS (Mean Opinion Score)**, bez udziaÅ‚u czÅ‚owieka.

Projekt bada, czy nowoczesne techniki uczenia maszynowego, w szczegÃ³lnoÅ›ci modele oparte na **gÅ‚Ä™bokich sieciach neuronowych**, sÄ… w stanie skutecznie przewidywaÄ‡ subiektywne oceny jakoÅ›ci mowy na podstawie cech akustycznych lub sygnaÅ‚u audio, w sposÃ³b porÃ³wnywalny z ocenÄ… ludzkÄ….

Projekt realizowany jest jako czÄ™Å›Ä‡ **pracy magisterskiej** i pozostaje w fazie rozwoju.

---

## ðŸ§  Architektury modeli

W projekcie zaimplementowano i przetestowano kilka architektur sieci neuronowych, w zaleÅ¼noÅ›ci od rodzaju zastosowanej reprezentacji sygnaÅ‚u mowy.

### 1ï¸âƒ£ Modele CNN (Mel-spektrogramy i MFCC)

Dla reprezentacji opartych na **mel-spektrogramach** oraz **wspÃ³Å‚czynnikach MFCC** zastosowano nastÄ™pujÄ…ce architektury:

- **CNN**  
  Konwolucyjna sieÄ‡ neuronowa przetwarzajÄ…ca dwuwymiarowe reprezentacje czasowo-czÄ™stotliwoÅ›ciowe.

- **CNN + GRU**  
  Ekstraktor cech oparty na CNN poÅ‚Ä…czony z warstwÄ… GRU w celu modelowania zaleÅ¼noÅ›ci czasowych.

- **CNN + LSTM**  
  Analogiczna architektura z wykorzystaniem warstw LSTM.

KaÅ¼da architektura trenowana jest **oddzielnie** dla mel-spektrogramÃ³w oraz MFCC.

---

### 2ï¸âƒ£ Modele oparte na wav2vec2.0

Dla pracy na surowym sygnale audio wykorzystano modele samouczÄ…ce siÄ™:

- **wav2vec2.0 + GRU**
- **wav2vec2.0 + LSTM**

W tym podejÅ›ciu model wav2vec2.0 peÅ‚ni rolÄ™ ekstraktora embeddingÃ³w mowy, ktÃ³re nastÄ™pnie przetwarzane sÄ… przez sieci rekurencyjne.

> Architektury konwolucyjne nie sÄ… stosowane bezpoÅ›rednio do embeddingÃ³w wav2vec2.0.

---

## ðŸŽ¼ Ekstrakcja cech akustycznych

W projekcie wykorzystano nastÄ™pujÄ…ce reprezentacje danych:

| Reprezentacja | ObsÅ‚ugiwane modele |
|---------------|-------------------|
| Mel-spektrogramy | CNN / CNN + GRU / CNN + LSTM |
| MFCC | CNN / CNN + GRU / CNN + LSTM |
| Embeddingi wav2vec2.0 | wav2vec2 + GRU / LSTM |

W ramach niniejszej pracy **nie zastosowano explicite statystycznej normalizacji cech akustycznych** (np. normalizacji Å›redniej i wariancji). Skalowanie cech realizowane jest poÅ›rednio przez warstwy sieci neuronowych.

---

## ðŸŽ¯ Skala MOS

Podczas uczenia modeli wartoÅ›ci MOS sÄ… normalizowane do zakresu:

\[
\text{MOS}_{\text{norm}} = \frac{\text{MOS} - 1}{4}
\]

Na etapie ewaluacji oraz wizualizacji wyniki sÄ… przeskalowywane z powrotem do standardowego zakresu **MOS âˆˆ [1, 5]**.

---

## ðŸ“Š Metryki ewaluacji

JakoÅ›Ä‡ modeli oceniana jest przy uÅ¼yciu nastÄ™pujÄ…cych miar:

- **MSE (Mean Squared Error)** â€“ bÅ‚Ä…d Å›redniokwadratowy  
- **RMSE (Root Mean Squared Error)** â€“ pierwiastek bÅ‚Ä™du Å›redniokwadratowego  
- **Pearson Correlation Coefficient** â€“ korelacja liniowa  
- **Spearman Rank Correlation Coefficient** â€“ korelacja rangowa  

Metryki obliczane sÄ… na zbiorze walidacyjnym.

---

## ðŸ“‚ Zbiory danych

Eksperymenty przeprowadzono z wykorzystaniem **NISQA Corpus**, zawierajÄ…cego nagrania mowy o zrÃ³Å¼nicowanych degradacjach jakoÅ›ciowych wraz z subiektywnymi ocenami MOS.

---

## ðŸš§ Status projektu

- âœ” Implementacja ekstrakcji cech  
- âœ” Implementacja architektur modeli  
- âœ” Pipeline treningu i walidacji  
- ðŸ”„ Strojenie hiperparametrÃ³w  
- ðŸ”„ Analiza wynikÃ³w eksperymentÃ³w  
- ðŸ”„ Opracowanie koÅ„cowej dokumentacji  

---

## ðŸ“Œ Uwagi

Repozytorium stanowi Å›rodowisko badawcze.  
Struktura projektu, architektury oraz procedury ewaluacyjne mogÄ… ulec zmianie w trakcie dalszych prac.

---

## ðŸ“„ Licencja

Projekt realizowany w celach naukowych i dydaktycznych.
